Predicting processor performance
========================================================


```{r}
data <- read.table('../data/training.csv', sep=",")
preds = c("Width", "ROBSize", "IQSize","LSQSize","RFSize","RFReadPorts","RFWritePorts","GshareSize",
  "BTBSize","BranchesAllowed","L1Icache","L1Dcache","L2Ucache","Depth")
vars = c(preds,"Delay")
names(data) = vars
```

Visualizing the dataset
-----------------------
```{r fig.width=7, fig.height=6}
plot(data$Delay)
plot(density(data$Delay))
plot(density(log(data$Delay)))
plot(density(data$Width))
plot(density(data$ROBSize))
plot(density(data$IQSize))
plot(density(data$LSQSize))
plot(density(data$RFSize))
plot(density(data$RFReadPorts))
plot(density(data$RFWritePorts))
plot(density(data$GshareSize))
plot(density(data$BTBSize))
plot(density(data$BranchesAllowed))
plot(density(data$L1Icache))
plot(density(data$L1Dcache))
plot(density(data$L2Ucache))
plot(density(data$Depth))
```
*Conclusion*: a logarithmic transformation of our target variable Delay seems to be appropriate.
Also, there are no outliers in Delay.

Getting relative variable importance using trees
-------------------------------------------------
```{r}
require(party)
require(lattice)
data.forest <- cforest(Delay~., data=data[, vars])
data.varimp <- sort(varimp(data.forest))
dotplot(data.varimp)
data.tree <- ctree(Delay~., data=data[, vars])
plot(data.tree)
```
*Conclusion*: L2Ucache and Depth are the important variables

Visualize L2Ucache and Depth
----------------------------
```{r}
     plot(data$Delay~data$L2Ucache)
     plot(log(data$Delay)~data$L2Ucache)
     plot(data$Delay~data$Depth)
     plot(log(data$Delay)~data$Depth)
```
*Conclusion*: L2Ucache seems not to have linear influence.
Depth might interact with a variable.

Defining utility functions
---------------------------
```{r}
#root mean square error
rmse <- function(y, yhat) {
  return(sqrt(mean((y-yhat)^2)))
}
     
#cross validation using RMSE
#returns mean of the k RMSEs
crossValidate <- function(modelFunction, formula, fullData, k=10) {
  group <- sample(1:k, nrow(fullData), replace=TRUE)
  #groupedData <- split(fullData,groups)
  responseVariable <- all.vars(formula)[1]
  errors <- c()
  for(i in 1:k) {
    model <- modelFunction(formula, data=fullData[group!=i,])
    predictions <- predict(model, fullData[group==i,])
    errors <- c(errors, rmse(data[group==i,c(responseVariable)], predictions))
  }
  return(mean(errors))
}
```

Using Linear Regression
-----------------------
With all predictors linear.
```{r}
formula = as.formula("Delay~.")
data.lm <- lm(formula, data=data)
summary(data.lm)
crossValidate(lm,formula,data)
     
formula = as.formula("log(Delay)~.")
data.lm <- lm(formula, data=data)
summary(data.lm)
crossValidate(lm,formula,data)
```
*Conclusion*: many predictors not significant, log(response) performs worse

Select the significant selectors iteratively:
```{r}
# formula = as.formula("Delay)~
#          Width+
#          ROBSize+
#          IQSize+
#          LSQSize+
#          RFSize+
#          RFReadPorts+
#          RFWritePorts+
#          GshareSize+
#          BTBSize+
#          BranchesAllowed+
#          L1Icache+
#          L1Dcache+
#          L2Ucache+
#          Depth")
formula = as.formula("Delay~
               IQSize+
               RFSize+
               BranchesAllowed+
               Depth+
               L2Ucache")
simple.lm <- lm(formula, data=data)
summary(simple.lm)
crossValidate(lm,formula,data)


formula = as.formula("log(Delay)~
               IQSize+
               RFSize+
               BranchesAllowed+
               Depth+
               L2Ucache")
simpleLog.lm <- lm(formula, data=data)
summary(simpleLog.lm)
crossValidate(lm,formula,data)

formula = as.formula("Delay~
               IQSize+
               poly(RFSize,2)+
               BranchesAllowed+
               Depth+
               Depth:I(log(L2Ucache))")
complex.lm <- lm(formula, data=data)
summary(complex.lm)
crossValidate(lm,formula,data)

plot(data$Delay, data$RFSize)
```
*Conclusion*: L2Ucache is a better predictor when log-transformed. Huge reduction of rmse when L2Ucache in interaction with Depth. 
RFSize squared is significant.

Regularized Linear Regression
-----
```{r}
reglm <- function(X, y, lambda) {
  #X: nxd, t(x)*X: dxd, I*lambda: dx1x1x1
  #inv*t(X)*y: dxd*dxn*nx1=dx1
  d <- ncol(X)
  I <- diag(d)
  return(solve(t(X)%*%X+lambda*I)%*%t(X)%*%y)
}

predict.reglm <- function(X, w) {
  #nxd*dx1=nx1
  return(X%*%w)
}

test.reglm <- function() {
  x <- seq(0,10,0.5)
  y <- x^2 + rnorm(length(x), 0, 5.0)
  plot(x,y)
  X <- as.matrix(x)
  w <- reglm(X,y,0.1)
  lines(X, predict.reglm(X,w),col="blue")
  addFeature <- function(x) {
    #x <- scale(x, mean(x), sd(x))
    X <- cbind(x, x^2,x^3,x^4,x^5,x^6)
    X <- scale(X, colMeans(X), apply(X,2,sd))
    X <- cbind(rep(1,nrow(X)),X)
     return(X)
  #  return(X)
  }
  X <- addFeature(x)
  w <- reglm(X,y,0)
  yhat <- predict.reglm(addFeature(x),w)
  lines(x, yhat, col="red")
  w <- reglm(X,y,0.1)
  yhat <- predict.reglm(addFeature(x),w)
  lines(x, yhat, col="brown")
}

cv.reglm <- function(X, y, lambda, k=10) {
  group <- sample(1:k, nrow(X), replace=TRUE)
  errors <- c()
  for(i in 1:k) {
    subY <- y[group==i]
    subX <- X[group==i,]
    nSubY <- y[group!=i]
    nSubX <- X[group!=i,]
    w <- reglm(nSubX,nSubY,lambda)
    predictions <- predict.reglm(subX,w)
    errors <- c(errors, rmse(subY, predictions))
  }
  return(mean(errors))
} 
```

Regularized Regression on our Dataset
---
```{r}
featureTransform <- function(df) {
  X <- cbind(df$RFSize, df$RFSize^2, df$IQSize, df$BranchesAllowed, df$Depth, log(df$L2Ucache), df$Depth*log(df$L2Ucache))
  X <- scale(X, colMeans(X), apply(X,2,sd))
  X <- cbind(rep(1,nrow(X)),X)
  return(X)
}
X <- featureTransform(data)
minError <- 2147483647
minLambda <- "toBeFilled"
for(lambda in c(0.00001, 0.0001,0.001,0.01,0.1,1,10,100,1000)) {
  cvError <- cv.reglm(X,data$Delay,lambda)
  if(cvError < minError) {
    minError <- cvError
    minLambda <- lambda
  }
}
minError
minLambda
weights.reglm <- reglm(X, data$Delay, minLambda)
```

GAM
----
```{r warning=FALSE}
require(mgcv)
formula = as.formula("Delay~
         s(RFSize)+
         BranchesAllowed+
         te(L2Ucache,Depth)")

complex.gam <- gam(formula, data=data)
summary(complex.gam)
vis.gam(complex.gam, view=c("L2Ucache", "Depth"), plot.type="contour", color="terrain", too.far=0.1)
AIC(complex.gam)
crossValidate(gam,formula,data)

data$fL2Ucache <- as.factor(data$L2Ucache)
formula = as.formula("Delay~
         s(RFSize)+
         BranchesAllowed*fL2Ucache+
         +s(Depth, by=fL2Ucache)")

complex.gam2 <- gam(formula, data=data)
summary(complex.gam2)
AIC(complex.gam2)
crossValidate(gam,formula,data)
```

Predict labels for validation set
-----------------------
```{r}
validation <- read.table("../data/validation.csv", sep=",")
names(validation) <- preds
write.table(predict(simple.lm,validation), file="valPredLMSimple.csv", row.names=FALSE, col.names=FALSE)
write.table(predict(simpleLog.lm,validation), file="valPredLMSimpleLog.csv", row.names=FALSE, col.names=FALSE)
write.table(predict(complex.lm,validation), file="valPredLMComplex.csv", row.names=FALSE, col.names=FALSE)
write.table(predict.reglm(featureTransform(validation), weights.reglm), file="valPredLMComplexReg.csv", row.names=FALSE, col.names=FALSE)
write.table(predict(complex.gam,validation), file="valPredGAM.csv", row.names=FALSE, col.names=FALSE)
validation$fL2Ucache <- as.factor(validation$L2Ucache)
write.table(predict(complex.gam2,validation), file="valPredGAM2.csv", row.names=FALSE, col.names=FALSE)
```
